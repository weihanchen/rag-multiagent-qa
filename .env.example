# ========================================
# RAG 多代理文件問答系統 - Ollama 本地模型配置
# ========================================

# Ollama 本地模型配置
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2:7b

# 向量資料庫配置
VECTOR_STORE_TYPE=faiss
VECTOR_STORE_PATH=./vector_store

# 系統配置 (針對本地模型優化)
MAX_TOKENS=2000
TEMPERATURE=0.3
CHUNK_SIZE=500
CHUNK_OVERLAP=100

# 代理配置
ENABLE_HUMAN_INPUT=false
MAX_ITERATIONS=10

# ========================================
# 性能優化說明
# ========================================
# CHUNK_SIZE=500      # 較小的chunk大小，節省記憶體
# MAX_TOKENS=2000     # 適中的token限制，平衡速度和質量
# TEMPERATURE=0.3     # 較低的溫度，提高答案一致性
# CHUNK_OVERLAP=100   # 適中的重疊，確保上下文連續性
