#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ollama æœ¬åœ°æ¨¡å‹æ¸¬è©¦è…³æœ¬
ç”¨æ–¼é©—è­‰ Ollama è¨­ç½®æ˜¯å¦æ­£ç¢º
"""

import os
import sys
from dotenv import load_dotenv

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

def test_ollama_connection():
    """æ¸¬è©¦ Ollama é€£æ¥"""
    print("ğŸ¦™ æ¸¬è©¦ Ollama é€£æ¥...")
    
    try:
        import requests
        
        # ç²å– Ollama é…ç½®
        base_url = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
        model = os.getenv("OLLAMA_MODEL", "llama2:7b")
        
        print(f"ğŸ“ é€£æ¥åœ°å€: {base_url}")
        print(f"ğŸ¤– æ¨¡å‹åç¨±: {model}")
        
        # æ¸¬è©¦åŸºæœ¬é€£æ¥
        print("\n1ï¸âƒ£ æ¸¬è©¦åŸºæœ¬é€£æ¥...")
        response = requests.get(f"{base_url}/api/tags", timeout=10)
        
        if response.status_code == 200:
            print("âœ… åŸºæœ¬é€£æ¥æˆåŠŸ")
            
            # ç²å–å¯ç”¨æ¨¡å‹
            models = response.json().get("models", [])
            model_names = [m["name"] for m in models]
            
            print(f"ğŸ“‹ å¯ç”¨æ¨¡å‹: {model_names}")
            
            # æª¢æŸ¥ç›®æ¨™æ¨¡å‹æ˜¯å¦å¯ç”¨
            if model in model_names:
                print(f"âœ… ç›®æ¨™æ¨¡å‹ {model} å¯ç”¨")
            else:
                print(f"âš ï¸  ç›®æ¨™æ¨¡å‹ {model} ä¸å¯ç”¨")
                print(f"ğŸ’¡ è«‹ä½¿ç”¨ 'ollama pull {model}' ä¸‹è¼‰æ¨¡å‹")
                return False
            
        else:
            print(f"âŒ åŸºæœ¬é€£æ¥å¤±æ•—: HTTP {response.status_code}")
            return False
        
        # æ¸¬è©¦æ¨¡å‹æ¨ç†
        print("\n2ï¸âƒ£ æ¸¬è©¦æ¨¡å‹æ¨ç†...")
        test_prompt = "Hello, how are you?"
        
        response = requests.post(
            f"{base_url}/api/generate",
            json={
                "model": model,
                "prompt": test_prompt,
                "stream": False
            },
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            print("âœ… æ¨¡å‹æ¨ç†æˆåŠŸ")
            print(f"ğŸ“ æ¸¬è©¦æç¤º: {test_prompt}")
            print(f"ğŸ¤– æ¨¡å‹å›æ‡‰: {result.get('response', '')[:100]}...")
        else:
            print(f"âŒ æ¨¡å‹æ¨ç†å¤±æ•—: HTTP {response.status_code}")
            print(f"éŒ¯èª¤è©³æƒ…: {response.text}")
            return False
        
        # æ¸¬è©¦åµŒå…¥åŠŸèƒ½
        print("\n3ï¸âƒ£ æ¸¬è©¦åµŒå…¥åŠŸèƒ½...")
        response = requests.post(
            f"{base_url}/api/embeddings",
            json={
                "model": model,
                "prompt": test_prompt
            },
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            embedding = result.get("embedding", [])
            print(f"âœ… åµŒå…¥åŠŸèƒ½æ­£å¸¸ï¼Œå‘é‡ç¶­åº¦: {len(embedding)}")
        else:
            print(f"âš ï¸  åµŒå…¥åŠŸèƒ½æ¸¬è©¦å¤±æ•—: HTTP {response.status_code}")
            print("ğŸ’¡ é€™å¯èƒ½å½±éŸ¿å‘é‡æœç´¢åŠŸèƒ½ï¼Œä½†ä¸æœƒé˜»æ­¢åŸºæœ¬ä½¿ç”¨")
        
        print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼Ollama è¨­ç½®æˆåŠŸï¼")
        return True
        
    except requests.exceptions.ConnectionError:
        print("âŒ ç„¡æ³•é€£æ¥åˆ° Ollama æœå‹™")
        print("ğŸ’¡ è«‹ç¢ºä¿ Ollama æœå‹™æ­£åœ¨é‹è¡Œ:")
        print("   ollama serve")
        return False
        
    except requests.exceptions.Timeout:
        print("âŒ é€£æ¥è¶…æ™‚")
        print("ğŸ’¡ è«‹æª¢æŸ¥ Ollama æœå‹™ç‹€æ…‹å’Œç¶²çµ¡é€£æ¥")
        return False
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return False

def test_config_validation():
    """æ¸¬è©¦é…ç½®é©—è­‰"""
    print("\nâš™ï¸  æ¸¬è©¦é…ç½®é©—è­‰...")
    
    try:
        from config import Config
        
        # é©—è­‰é…ç½®
        Config.validate()
        print("âœ… é…ç½®é©—è­‰é€šé")
        
        # æ¸¬è©¦ LLM é…ç½®
        llm_config = Config.get_llm_config()
        print(f"ğŸ¤– LLM é…ç½®: {llm_config}")
        
        return True
        
    except Exception as e:
        print(f"âŒ é…ç½®é©—è­‰å¤±æ•—: {str(e)}")
        return False

def test_agent_initialization():
    """æ¸¬è©¦ä»£ç†åˆå§‹åŒ–"""
    print("\nğŸ¤– æ¸¬è©¦ä»£ç†åˆå§‹åŒ–...")
    
    try:
        from agents.multi_agent_manager import MultiAgentManager
        
        # åˆå§‹åŒ–ç®¡ç†å™¨
        manager = MultiAgentManager()
        print("âœ… å¤šä»£ç†ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # æ¸¬è©¦é€£æ¥
        result = manager.test_model_connection()
        print(f"ğŸ”— é€£æ¥æ¸¬è©¦çµæœ: {result}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ä»£ç†åˆå§‹åŒ–å¤±æ•—: {str(e)}")
        return False

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ Ollama æœ¬åœ°æ¨¡å‹è¨­ç½®æ¸¬è©¦")
    print("=" * 50)
    
    # é‹è¡Œæ¸¬è©¦
    tests = [
        test_ollama_connection,
        test_config_validation,
        test_agent_initialization
    ]
    
    passed = 0
    total = len(tests)
    
    for test in tests:
        try:
            if test():
                passed += 1
        except Exception as e:
            print(f"âŒ æ¸¬è©¦ {test.__name__} åŸ·è¡Œå¤±æ•—: {str(e)}")
    
    print("\n" + "=" * 50)
    print(f"ğŸ“Š æ¸¬è©¦çµæœ: {passed}/{total} é€šé")
    
    if passed == total:
        print("ğŸ‰ æ­å–œï¼Ollama è¨­ç½®å®Œå…¨æˆåŠŸï¼")
        print("ğŸ’¡ ç¾åœ¨å¯ä»¥é–‹å§‹ä½¿ç”¨æœ¬åœ°æ¨¡å‹é€²è¡Œå•ç­”äº†")
    else:
        print("âš ï¸  éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥è¨­ç½®ä¸¦é‡è©¦")
        print("ğŸ“š åƒè€ƒ OLLAMA_SETUP.md ç²å–è©³ç´°å¹«åŠ©")

if __name__ == "__main__":
    main()
